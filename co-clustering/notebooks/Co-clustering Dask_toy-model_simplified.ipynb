{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-clustering with Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:63642</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:63642' processes=2 threads=2, memory=17.18 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCluster(threads_per_worker=1,\n",
    "                       n_workers=2,\n",
    "                       processes=True)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "from dask.distributed import as_completed, get_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idivdist2(Z, X, Y, epsilon):\n",
    "    \"\"\" Cost function \"\"\"\n",
    "    Y = Y + epsilon\n",
    "    d = da.dot(X, Y) - da.dot(Z, da.log(Y))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_clusters(n_el, n_clusters, chuncks=None):\n",
    "    \"\"\" Initialize cluster occupation matrix \"\"\"\n",
    "    cluster_idx = np.mod(np.arange(n_el), n_clusters)\n",
    "    cluster_idx = np.random.permutation(cluster_idx)\n",
    "    eye = da.eye(n_clusters, dtype=np.int)  # specify chunck here?\n",
    "    return eye[cluster_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coclustering(Z, k, l, errobj, niters, epsilon):\n",
    "    \"\"\" \n",
    "    Run the co-clustering \n",
    "    \n",
    "    :param Z: m x n data matrix\n",
    "    :param k: num row clusters\n",
    "    :param l: num col clusters\n",
    "    :param errobj: precision of obj fun for convergence\n",
    "    :param niters: max iterations\n",
    "    :param epsilon: precision of matrix elements\n",
    "    :return: final row clustering, final column clustering\n",
    "    \"\"\"\n",
    "    client = get_client()\n",
    "\n",
    "    [m, n] = Z.shape\n",
    "\n",
    "    R = initialize_clusters(m, k)\n",
    "    C = initialize_clusters(n, l)\n",
    "    # the following lines return the original initialization for the toy model\n",
    "#     R = da.eye(k, dtype=np.int)\n",
    "#     R = R[[1, 1, 1, 0, 0, 0]]\n",
    "#     C = da.eye(l, dtype=np.int)\n",
    "#     C = C[[0, 1, 0, 2, 0, 0, 2, 2]]\n",
    "\n",
    "    e = 2 * errobj\n",
    "    old_e = 0\n",
    "    s = 1\n",
    "\n",
    "    while (abs(e - old_e) > errobj) & (s <= niters):\n",
    "\n",
    "        CoCavg = (da.dot(da.dot(R.T, Z), C) + Z.mean() * epsilon) / (da.dot(da.dot(R.T, da.ones((m, n))), C) + epsilon)\n",
    "\n",
    "        d_row = idivdist2(Z, da.ones((m, n)), da.dot(C, CoCavg.T), epsilon)\n",
    "        idx_row = da.argmin(d_row, axis=1)\n",
    "        R = da.eye(k, dtype=np.int)[idx_row]\n",
    "\n",
    "        d_col = idivdist2(Z.T, da.ones((n, m)), da.dot(R, CoCavg), epsilon)\n",
    "        idx_col = da.argmin(d_col, axis=1)\n",
    "        C = da.eye(l, dtype=np.int)[idx_col]\n",
    "\n",
    "        minvals_da = da.min(d_col, axis=1)\n",
    "\n",
    "        old_e = e\n",
    "        e = da.sum(da.power(minvals_da, 1))  # power 1 divergence, power 2 euclidean\n",
    "        R, C, e = client.persist([R, C, e])\n",
    "\n",
    "        e = e.compute()\n",
    "        # the following lines are a workaround to e.compute(), required if:\n",
    "        # - the function is submitted to the worker\n",
    "        # - multi-threaded workers are employed\n",
    "        # this is because of a bug in Dask: https://github.com/dask/distributed/issues/3827\n",
    "#         e = client.compute(e)\n",
    "#         secede()\n",
    "#         e = e.result()\n",
    "#         rejoin()\n",
    "\n",
    "        s = s + 1\n",
    "    return R, C, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_runs_memory(Z, k, l, errobj, niters, epsilon, nruns):\n",
    "    \"\"\" Memory efficient loop over runs \"\"\"\n",
    "    R_min, C_min, e_min = None, None, 0.\n",
    "    for r in range(nruns):\n",
    "        R, C, e = coclustering(Z, k, l, errobj, niters, epsilon)\n",
    "        if e < e_min:\n",
    "            R_min, C_min, e_min = R, C, e\n",
    "    return R_min, C_min, e_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_runs_performance(Z, k, l, errobj, niters, epsilon, nruns):\n",
    "    \"\"\" Faster implementation of loop over runs \"\"\"\n",
    "    # we need to specify pure=False\n",
    "    futures = [client.submit(coclustering, Z, k, l, errobj, niters, epsilon, pure=False)  \n",
    "               for r in range(nruns)]\n",
    "    R_min, C_min, e_min = None, None, 0.\n",
    "    for future, result in as_completed(futures,\n",
    "                                       with_results=True,\n",
    "                                       raise_errors=False):\n",
    "        R, C, e = result\n",
    "        if e < e_min:\n",
    "            R_min, C_min, e_min = R, C, e\n",
    "    return R_min, C_min, e_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2  # num clusters in rows\n",
    "l = 3  # num clusters in columns\n",
    "errobj, niters, nruns, epsilon = 0.00001, 100, 15, 10e-8\n",
    "Z = np.array([[24.,  44.,   5.,   6.,  26., 100.,  20.,  95.],\n",
    "       [38.,  14.,  10.,  36.,  56.,  75.,   0.,  26.],\n",
    "       [0.,  54.,  59.,  45.,  87.,  65.,  28.,  36.],\n",
    "       [34.,  45.,  95.,  54.,  78.,  56.,  82.,  63.],\n",
    "       [4.,  63.,  82.,  56.,  36.,  96.,  45.,  34.],\n",
    "       [24.,  25.,   9.,   2.,  28.,  57.,  76.,  23.]])\n",
    "Z = da.from_array(Z, chunks=(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total elapsed 6.7966179847717285\n",
      "-6110.440775184063\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]]\n",
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# original implementation\n",
    "start_time = time.time()\n",
    "R, C, e = multiple_runs_performance(Z, k, l, errobj, niters, epsilon, nruns)\n",
    "print(\"total elapsed\", time.time() - start_time)\n",
    "print(e)\n",
    "print(R.compute())\n",
    "print(C.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total elapsed 17.543510913848877\n",
      "-6110.440775184063\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]]\n",
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# memory-efficient implementation\n",
    "start_time = time.time()\n",
    "R, C, e = multiple_runs_memory(Z, k, l, errobj, niters, epsilon, nruns)\n",
    "print(\"total elapsed\", time.time() - start_time)\n",
    "print(e)\n",
    "print(R.compute())\n",
    "print(C.compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
